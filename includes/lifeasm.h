

        // Code generated by rule2asm.py

        // Tile size: 32 * 32
        // Rule: b3s23

        uint32_t e[ROWS + 16];
        for (int i = 0; i < 8; i++) {e[ROWS + i] = MIDDLE28; }
        for (int i = 0; i < 8; i++) {e[ROWS + 8 + i] = (1 + i) % 8; }

        if (history) {for (int i = 2; i < ROWS - 2; i++) {sqt->hist[i] |= sqt->d[i]; }}
        asm (
                "vmovdqu 160(%1), %%ymm13 \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu (%0), %%ymm5 \n\t"
                "vpsrld $1, %%ymm5, %%ymm0 \n\t"
                "vpslld $1, %%ymm5, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm6 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm7 \n\t"
                "vpand %%ymm5, %%ymm6, %%ymm1 \n\t"
                "vpxor %%ymm5, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm1, %%ymm7, %%ymm7 \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 32(%0), %%ymm2 \n\t"
                "vpsrld $1, %%ymm2, %%ymm0 \n\t"
                "vpslld $1, %%ymm2, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm3 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm4 \n\t"
                "vpand %%ymm2, %%ymm3, %%ymm1 \n\t"
                "vpxor %%ymm2, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm1, %%ymm4, %%ymm4 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm3, %%ymm6, %%ymm8 \n\t"
                "vpblendd $1, %%ymm4, %%ymm7, %%ymm9 \n\t"
                "vpblendd $3, %%ymm3, %%ymm6, %%ymm10 \n\t"
                "vpblendd $3, %%ymm4, %%ymm7, %%ymm11 \n\t"
                "vpblendd $1, %%ymm2, %%ymm5, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm7, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm9, %%ymm7, %%ymm7 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm7, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // store result:
                "vmovdqu %%ymm10, (%1) \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 64(%0), %%ymm5 \n\t"
                "vpsrld $1, %%ymm5, %%ymm0 \n\t"
                "vpslld $1, %%ymm5, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm6 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm7 \n\t"
                "vpand %%ymm5, %%ymm6, %%ymm1 \n\t"
                "vpxor %%ymm5, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm1, %%ymm7, %%ymm7 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm6, %%ymm3, %%ymm8 \n\t"
                "vpblendd $1, %%ymm7, %%ymm4, %%ymm9 \n\t"
                "vpblendd $3, %%ymm6, %%ymm3, %%ymm10 \n\t"
                "vpblendd $3, %%ymm7, %%ymm4, %%ymm11 \n\t"
                "vpblendd $1, %%ymm5, %%ymm2, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm4, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm9, %%ymm4, %%ymm4 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm4, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // store result:
                "vmovdqu %%ymm10, 32(%1) \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 96(%0), %%ymm2 \n\t"
                "vpsrld $1, %%ymm2, %%ymm0 \n\t"
                "vpslld $1, %%ymm2, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm3 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm4 \n\t"
                "vpand %%ymm2, %%ymm3, %%ymm1 \n\t"
                "vpxor %%ymm2, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm1, %%ymm4, %%ymm4 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm3, %%ymm6, %%ymm8 \n\t"
                "vpblendd $1, %%ymm4, %%ymm7, %%ymm9 \n\t"
                "vpblendd $3, %%ymm3, %%ymm6, %%ymm10 \n\t"
                "vpblendd $3, %%ymm4, %%ymm7, %%ymm11 \n\t"
                "vpblendd $1, %%ymm2, %%ymm5, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm7, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm9, %%ymm7, %%ymm7 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm7, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // store result:
                "vmovdqu %%ymm10, 64(%1) \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm6, %%ymm3, %%ymm8 \n\t"
                "vpblendd $1, %%ymm7, %%ymm4, %%ymm9 \n\t"
                "vpblendd $3, %%ymm6, %%ymm3, %%ymm10 \n\t"
                "vpblendd $3, %%ymm7, %%ymm4, %%ymm11 \n\t"
                "vpblendd $1, %%ymm5, %%ymm2, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm4, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm9, %%ymm4, %%ymm4 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm4, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // store result:
                "vmovdqu %%ymm10, 96(%1) \n\t"
                : /* no output operands */ 
                : "r" (sqt->d), "r" (e) 
                : "xmm0", "xmm1", "xmm2", "xmm3", "xmm4", "xmm5", "xmm6", "xmm7", "xmm8", "xmm9", "xmm10", "xmm11", "xmm12", "xmm13", "xmm14", "xmm15", "memory");

        if (history) {for (int i = 2; i < ROWS - 2; i++) {sqt->hist[i] |= e[i-1]; }}
        asm (
                "vmovdqu 128(%1), %%ymm14 \n\t"
                "vmovdqu 160(%1), %%ymm13 \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu (%1), %%ymm5 \n\t"
                "vpsrld $1, %%ymm5, %%ymm0 \n\t"
                "vpslld $1, %%ymm5, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm6 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm7 \n\t"
                "vpand %%ymm5, %%ymm6, %%ymm1 \n\t"
                "vpxor %%ymm5, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm1, %%ymm7, %%ymm7 \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 32(%1), %%ymm2 \n\t"
                "vpsrld $1, %%ymm2, %%ymm0 \n\t"
                "vpslld $1, %%ymm2, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm3 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm4 \n\t"
                "vpand %%ymm2, %%ymm3, %%ymm1 \n\t"
                "vpxor %%ymm2, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm1, %%ymm4, %%ymm4 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm3, %%ymm6, %%ymm8 \n\t"
                "vpblendd $1, %%ymm4, %%ymm7, %%ymm9 \n\t"
                "vpblendd $3, %%ymm3, %%ymm6, %%ymm10 \n\t"
                "vpblendd $3, %%ymm4, %%ymm7, %%ymm11 \n\t"
                "vpblendd $1, %%ymm2, %%ymm5, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm7, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm9, %%ymm7, %%ymm7 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm7, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // determine diff:
                "vpand %%ymm14, %%ymm10, %%ymm10 \n\t"
                "vmovdqu 8(%0), %%ymm8 \n\t"
                "vpandn %%ymm8, %%ymm14, %%ymm11 \n\t"
                "vpor %%ymm10, %%ymm11, %%ymm11 \n\t"
                "vmovdqu %%ymm11, 8(%0) \n\t"
                "vpxor %%ymm11, %%ymm8, %%ymm15 \n\t"
                // save diff:
                "vmovdqu %%ymm15, (%1) \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 64(%1), %%ymm5 \n\t"
                "vpsrld $1, %%ymm5, %%ymm0 \n\t"
                "vpslld $1, %%ymm5, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm6 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm7 \n\t"
                "vpand %%ymm5, %%ymm6, %%ymm1 \n\t"
                "vpxor %%ymm5, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm1, %%ymm7, %%ymm7 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm6, %%ymm3, %%ymm8 \n\t"
                "vpblendd $1, %%ymm7, %%ymm4, %%ymm9 \n\t"
                "vpblendd $3, %%ymm6, %%ymm3, %%ymm10 \n\t"
                "vpblendd $3, %%ymm7, %%ymm4, %%ymm11 \n\t"
                "vpblendd $1, %%ymm5, %%ymm2, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm4, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm9, %%ymm4, %%ymm4 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm4, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // determine diff:
                "vpand %%ymm14, %%ymm10, %%ymm10 \n\t"
                "vmovdqu 40(%0), %%ymm8 \n\t"
                "vpandn %%ymm8, %%ymm14, %%ymm11 \n\t"
                "vpor %%ymm10, %%ymm11, %%ymm11 \n\t"
                "vmovdqu %%ymm11, 40(%0) \n\t"
                "vpxor %%ymm11, %%ymm8, %%ymm8 \n\t"
                "vpor %%ymm8, %%ymm15, %%ymm15 \n\t"
                // calculate row-wise parity and carry:
                "vmovdqu 96(%1), %%ymm2 \n\t"
                "vpsrld $1, %%ymm2, %%ymm0 \n\t"
                "vpslld $1, %%ymm2, %%ymm1 \n\t"
                "vpxor %%ymm0, %%ymm1, %%ymm3 \n\t"
                "vpand %%ymm0, %%ymm1, %%ymm4 \n\t"
                "vpand %%ymm2, %%ymm3, %%ymm1 \n\t"
                "vpxor %%ymm2, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm1, %%ymm4, %%ymm4 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm3, %%ymm6, %%ymm8 \n\t"
                "vpblendd $1, %%ymm4, %%ymm7, %%ymm9 \n\t"
                "vpblendd $3, %%ymm3, %%ymm6, %%ymm10 \n\t"
                "vpblendd $3, %%ymm4, %%ymm7, %%ymm11 \n\t"
                "vpblendd $1, %%ymm2, %%ymm5, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm7, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm6, %%ymm6 \n\t"
                "vpor %%ymm9, %%ymm7, %%ymm7 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm6, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm7, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // determine diff:
                "vpand %%ymm14, %%ymm10, %%ymm10 \n\t"
                "vmovdqu 72(%0), %%ymm8 \n\t"
                "vpandn %%ymm8, %%ymm14, %%ymm11 \n\t"
                "vpor %%ymm10, %%ymm11, %%ymm11 \n\t"
                "vmovdqu %%ymm11, 72(%0) \n\t"
                "vpxor %%ymm11, %%ymm8, %%ymm8 \n\t"
                "vpor %%ymm8, %%ymm15, %%ymm15 \n\t"
                // apply vertical bitshifts:
                "vpblendd $1, %%ymm6, %%ymm3, %%ymm8 \n\t"
                "vpblendd $1, %%ymm7, %%ymm4, %%ymm9 \n\t"
                "vpblendd $3, %%ymm6, %%ymm3, %%ymm10 \n\t"
                "vpblendd $3, %%ymm7, %%ymm4, %%ymm11 \n\t"
                "vpblendd $1, %%ymm5, %%ymm2, %%ymm12 \n\t"
                "vpermd %%ymm8, %%ymm13, %%ymm8 \n\t"
                "vpermd %%ymm9, %%ymm13, %%ymm9 \n\t"
                "vpermq $57, %%ymm10, %%ymm10 \n\t"
                "vpermq $57, %%ymm11, %%ymm11 \n\t"
                "vpermd %%ymm12, %%ymm13, %%ymm12 \n\t"
                // apply vertical full-adders:
                "vpxor %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpxor %%ymm4, %%ymm9, %%ymm9 \n\t"
                "vpxor %%ymm8, %%ymm10, %%ymm10 \n\t"
                "vpxor %%ymm9, %%ymm11, %%ymm11 \n\t"
                "vpor %%ymm8, %%ymm3, %%ymm3 \n\t"
                "vpor %%ymm9, %%ymm4, %%ymm4 \n\t"
                "vpand %%ymm10, %%ymm8, %%ymm8 \n\t"
                "vpand %%ymm11, %%ymm9, %%ymm9 \n\t"
                "vpandn %%ymm3, %%ymm8, %%ymm8 \n\t"
                "vpandn %%ymm4, %%ymm9, %%ymm9 \n\t"
#include "lifelogic.h"
                // dodgy vertical bit-masking hack:
                "vpxor %%ymm14, %%ymm14, %%ymm0 \n\t"
                "vpblendd $15, %%ymm14, %%ymm0, %%ymm14 \n\t"
                // determine diff:
                "vpand %%ymm14, %%ymm10, %%ymm10 \n\t"
                "vmovdqu 104(%0), %%ymm8 \n\t"
                "vpandn %%ymm8, %%ymm14, %%ymm11 \n\t"
                "vpor %%ymm10, %%ymm11, %%ymm11 \n\t"
                "vmovdqu %%ymm11, 104(%0) \n\t"
                "vpxor %%ymm11, %%ymm8, %%ymm8 \n\t"
                "vpor %%ymm8, %%ymm15, %%ymm15 \n\t"
                // save diffs:
                "vmovdqu %%ymm8, 64(%1) \n\t"
                "vmovdqu %%ymm15, 32(%1) \n\t"
                : /* no output operands */ 
                : "r" (sqt->d), "r" (e) 
                : "xmm0", "xmm1", "xmm2", "xmm3", "xmm4", "xmm5", "xmm6", "xmm7", "xmm8", "xmm9", "xmm10", "xmm11", "xmm12", "xmm13", "xmm14", "xmm15", "memory");

        // The diffs we're interested in:
        uint32_t topdiff = e[0] | e[1];
        uint32_t bigdiff = e[8] | e[9] | e[10] | e[11] | e[12] | e[13] | e[14] | e[15];
        uint32_t botdiff = e[18] | e[19];


        // End of generated code

